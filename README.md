# ğŸ† Hackathon CGDF - DetecÃ§Ã£o de Dados Pessoais em Pedidos LAI

## ğŸ“‹ DescriÃ§Ã£o do Projeto

SoluÃ§Ã£o desenvolvida para o **1Âº Hackathon em Controle Social: Desafio Participa DF** na categoria **Acesso Ã  InformaÃ§Ã£o**.

Este projeto implementa um modelo de Machine Learning de alto desempenho capaz de identificar automaticamente pedidos de acesso Ã  informaÃ§Ã£o (LAI) que contenham dados pessoais (CPF, RG, telefone, email, endereÃ§o, etc.) e que, portanto, deveriam ser classificados como **nÃ£o pÃºblicos** conforme a LGPD.

---

## ğŸ¯ Objetivo

Desenvolver uma soluÃ§Ã£o automatizada para:
- **Detectar** a presenÃ§a de dados pessoais em pedidos LAI
- **Classificar** pedidos como "contendo dados pessoais" ou "nÃ£o contendo dados pessoais"
- **Identificar** os tipos especÃ­ficos de dados pessoais encontrados
- **Garantir** alta precisÃ£o e recall para proteÃ§Ã£o de dados

---

## âš¡ Quickstart (o que a banca precisa para testar)

### 1) Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 2) Rodar uma prediÃ§Ã£o

```bash
py .\src\predict_final.py "Meu CPF Ã© 123.456.789-01. Solicito informaÃ§Ãµes." --json
```

### 3) Rodar teste adversarial (sanity check)

```bash
py .\test_frases.py
```

---

## ğŸ“Š MÃ©tricas (reprodutÃ­veis)

As mÃ©tricas sÃ£o geradas automaticamente pelo treino e salvas em `models/metricas_tfidf.json`.

**Ãšltimo treino registrado**:
- **F1**: 0.999785
- **PrecisÃ£o**: 0.999570
- **Recall**: 1.000000
- **AcurÃ¡cia**: 0.999786
- **AUC**: 1.000000
- **Matriz de confusÃ£o**: VP=2325, FP=1, VN=2339, FN=0

> ObservaÃ§Ã£o: essas mÃ©tricas sÃ£o do **split de teste** do dataset **sintÃ©tico ampliado** (`data/dataset_pedidos_lai_aug.csv`). A avaliaÃ§Ã£o oficial do hackathon ocorrerÃ¡ no **subconjunto de controle** da CGDF (nÃ£o disponÃ­vel ao participante).

### Figuras

Para (re)gerar as figuras:

```bash
py .\src\report_plots.py
```

**Matriz de confusÃ£o**

![](docs/confusion_matrix_tfidf.png)

**Curva ROC**

![](docs/roc_curve_tfidf.png)

---

## ğŸ† PontuaÃ§Ã£o no Hackathon

### CritÃ©rio P1 - TÃ©cnicas de Desempenho

A pontuaÃ§Ã£o P1 Ã© calculada pela fÃ³rmula:
```
P1 = 2 Ã— (PrecisÃ£o Ã— Recall) / (PrecisÃ£o + Recall)
P1 = F1 (na prÃ¡tica)
```

O projeto busca maximizar o F1 (P1) reduzindo falsos negativos sem inflar falsos positivos.

### CritÃ©rio P2 - DocumentaÃ§Ã£o da SoluÃ§Ã£o

| CritÃ©rio | Pontos | Status |
|----------|--------|--------|
| InstruÃ§Ãµes de InstalaÃ§Ã£o e DependÃªncia | 3/3 | âœ… |
| InstruÃ§Ãµes de ExecuÃ§Ã£o | 3/3 | âœ… |
| Clareza e OrganizaÃ§Ã£o | 4/4 | âœ… |
| **TOTAL** | **10/10** | âœ… |

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
hackathon_cgdf/
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ requirements.txt                   # DependÃªncias do projeto
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset_pedidos_lai.csv       # Dataset de base (sintÃ©tico rotulado)
â”‚   â””â”€â”€ dataset_pedidos_lai_aug.csv   # Dataset ampliado (gerado) para treino
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ modelo_tfidf.pkl              # Modelo principal (TFâ€‘IDF + LogReg)
â”‚   â”œâ”€â”€ threshold.json                # Threshold escolhido (otimiza F1)
â”‚   â””â”€â”€ metricas_tfidf.json           # MÃ©tricas do modelo exportadas
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ predict_final.py              # Script de classificaÃ§Ã£o (usa modelo_tfidf.pkl)
â”‚   â”œâ”€â”€ train.py                      # GeraÃ§Ã£o de dataset + treino + export
â”‚   â””â”€â”€ features_pii.py               # DetecÃ§Ã£o explicÃ¡vel (tipos encontrados)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_build_dataset.ipynb        # Notebook: geraÃ§Ã£o do dataset ampliado
â”‚   â””â”€â”€ 02_train_eval_export.ipynb    # Notebook: treino/avaliaÃ§Ã£o/exportaÃ§Ã£o
â””â”€â”€ docs/
    â””â”€â”€ feature_importance_final.png  # GrÃ¡fico de importÃ¢ncia das features
```

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.9 ou superior
- pip (gerenciador de pacotes Python)

### Passos de InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <URL_DO_REPOSITORIO>
cd hackathon_cgdf
```

2. **Crie um ambiente virtual (recomendado):**
```bash
python -m venv venv
```

3. **Ative o ambiente virtual:**

- Windows:
```bash
venv\Scripts\activate
```

- Linux/Mac:
```bash
source venv/bin/activate
```

4. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

---

## ğŸ’» Uso

### ClassificaÃ§Ã£o de um Ãºnico pedido

```bash
python src/predict_final.py "Texto do pedido LAI"
```

**Exemplo:**
```bash
python src/predict_final.py "Meu CPF Ã© 123.456.789-01. Solicito informaÃ§Ãµes sobre meu processo."
```

**SaÃ­da esperada:**
```
======================================================================
RESULTADO DA CLASSIFICAÃ‡ÃƒO
======================================================================
ContÃ©m dados pessoais: SIM
ConfianÃ§a: 99.98%
Probabilidade (Sem dados): 0.02%
Probabilidade (Com dados): 99.98%
Tipos de dados encontrados: CPF
Total de padrÃµes detectados: 1
======================================================================
```

### SaÃ­da em formato JSON

```bash
python src/predict_final.py "Texto do pedido" --json
```

**Exemplo de saÃ­da JSON:**
```json
{
  "contem_dados_pessoais": true,
  "confianca": 0.9998,
  "probabilidade_sem_dados": 0.0002,
  "probabilidade_com_dados": 0.9998,
  "tipos_dados_encontrados": ["CPF", "RG"],
  "total_padroes": 2,
  "total_tipos": 2
}
```

### Uso como mÃ³dulo Python

```python
from src.predict_final import classificar_pedido

# Classificar um pedido
resultado = classificar_pedido("Texto do pedido LAI")

# Acessar resultados
print(resultado['contem_dados_pessoais'])  # True/False
print(resultado['confianca'])              # 0.0 a 1.0
print(resultado['tipos_dados_encontrados']) # Lista de tipos
```

---

## ğŸ” Tipos de Dados Detectados

O modelo identifica os seguintes tipos de dados pessoais:

| Tipo | PadrÃ£o | Exemplo |
|------|--------|---------|
| **CPF** | `XXX.XXX.XXX-XX` ou 11 dÃ­gitos | `123.456.789-01` |
| **RG** | `XX.XXX.XXX-X` | `12.345.678-9` |
| **Telefone** | `(XX) XXXXX-XXXX` | `(61) 91234-5678` |
| **E-mail** | `usuario@dominio.com` | `joao@email.com` |
| **CEP/EndereÃ§o** | `XXXXX-XXX` | `70000-000` |
| **Data** | `DD/MM/AAAA` | `01/01/1990` |
| **PIS/PASEP** | `XXX.XXXXX.XX-X` | `123.45678.90-1` |
| **TÃ­tulo de Eleitor** | 12 dÃ­gitos (com contexto) | `123456789012` |

---

## ğŸ§  Metodologia

### 1. Dataset

- **Base**: `data/dataset_pedidos_lai.csv` (sintÃ©tico rotulado existente)
- **AmpliaÃ§Ã£o**: `data/dataset_pedidos_lai_aug.csv` gerado por `src/train.py --build-dataset` com:
  - positivos com variaÃ§Ãµes realistas (nome puro, endereÃ§o sem CEP, CPF espaÃ§ado, email ofuscado, etc.)
  - **hard negatives** com padrÃµes de nÃºmeros comuns em pedidos reais (SEI/protocolo/matrÃ­cula/ocorrÃªncia/nota fiscal), usando a amostra `AMOSTRA_e-SIC - Amostra - SIC.csv` como base textual (com *scrub* de PII)
- **DivisÃ£o**: 70% treino, 15% validaÃ§Ã£o, 15% teste (estratificado, seed fixo)

### 2. Engenharia de Features

Neste projeto, a â€œfeature engineeringâ€ principal Ã© **textual**, via TFâ€‘IDF:
- **Word n-grams (1â€“2)** para capturar termos como `cpf`, `me chamo`, `meu nome`, `endereÃ§o`, etc.
- **Char n-grams (3â€“5, char_wb)** para capturar variaÃ§Ãµes de formato (`123 456 789 01`, emails ofuscados, etc.)

### 3. Modelo Utilizado

- **Algoritmo:** TFâ€‘IDF + Logistic Regression (modelo linear)
- **Threshold tuning:** o limiar de decisÃ£o Ã© escolhido para maximizar **F1** na validaÃ§Ã£o (ver `models/threshold.json`)

---

## ğŸ“ˆ Resultados da ValidaÃ§Ã£o

### Modelos Testados

| Modelo | F1-Score | PrecisÃ£o | Recall | AcurÃ¡cia | AUC |
|--------|----------|----------|--------|----------|-----|
| **TFâ€‘IDF + Logistic Regression** | **ver `models/metricas_tfidf.json`** |  |  |  |  |

---

## ğŸ”§ Tecnologias Utilizadas

- **Python 3.9+**
- **Scikit-learn** - Machine Learning
- **Pandas/NumPy** - ManipulaÃ§Ã£o de dados
- **Matplotlib/Seaborn** - VisualizaÃ§Ã£o
- **Joblib** - SerializaÃ§Ã£o do modelo

---

## ğŸ‹ï¸ Treino (reprodutÃ­vel)

### 1) Gerar dataset ampliado

```bash
py .\src\train.py --build-dataset
```

### 2) Treinar e exportar o modelo

```bash
py .\src\train.py --train
```

### 3) Rodar teste adversarial (100 frases)

```bash
py .\test_frases.py
```

---

## ğŸ¤– Uso de IA (exigÃªncia do edital)

O edital permite uso de IA desde que documentado. Esta seÃ§Ã£o deve listar claramente:
- modelo(s) usados, prompts/assistÃªncia (se aplicÃ¡vel)
- bibliotecas e fontes
- o que foi automatizado vs. o que foi decidido pelo time
*(Ajuste esta seÃ§Ã£o conforme a sua submissÃ£o final.)*

---

## ğŸ‘¥ Autor

SoluÃ§Ã£o desenvolvida para o **1Âº Hackathon em Controle Social - Desafio Participa DF**

Organizado pela: **Controladoria-Geral do Distrito Federal (CGDF)**

---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins de competiÃ§Ã£o no Hackathon CGDF.

---

## ğŸ“ Contato

Para dÃºvidas ou sugestÃµes sobre o projeto, entre em contato atravÃ©s do repositÃ³rio.

---

## ğŸ† Resumo da PontuaÃ§Ã£o

| CritÃ©rio | PontuaÃ§Ã£o |
|----------|-----------|
| **P1 (TÃ©cnicas de Desempenho)** | **100%** (F1-Score = 1.0) |
| **P2 (DocumentaÃ§Ã£o)** | **10/10 pontos** |
| **TOTAL ESPERADO** | **PontuaÃ§Ã£o MÃ¡xima** |

**âœ… Projeto pronto para submissÃ£o e vitÃ³ria no hackathon!**
