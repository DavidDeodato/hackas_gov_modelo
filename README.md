# Hackathon CGDF - Detec√ß√£o de Dados Pessoais em Pedidos LAI

## Descri√ß√£o do Projeto

Solu√ß√£o desenvolvida para o **1¬∫ Hackathon em Controle Social: Desafio Participa DF** na categoria **Acesso √† Informa√ß√£o**.

Este projeto implementa um modelo de Machine Learning capaz de identificar automaticamente pedidos de acesso √† informa√ß√£o (LAI) que contenham dados pessoais (ex.: CPF, RG, telefone, e-mail, endere√ßo, nome) e que, portanto, deveriam ser classificados como **n√£o p√∫blicos** conforme a LGPD.

---

## Objetivo

Entregar um modelo reprodut√≠vel que maximize o F1 (P1 do edital) e seja simples de executar e auditar.

---

## Execu√ß√£o r√°pida

### 1) Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

### 2) Rodar uma predi√ß√£o

```bash
py .\src\predict_final.py "Meu CPF √© 123.456.789-01. Solicito informa√ß√µes." --json
```

### 3) Rodar teste adversarial (sanity check)

```bash
py .\test_frases.py
```

---

## M√©tricas (reprodut√≠veis)

As m√©tricas s√£o geradas automaticamente pelo treino e salvas em `models/metricas_tfidf.json`.

√öltimo treino registrado (ver `models/metricas_tfidf.json`):
- **F1**: 0.999785
- **Precis√£o**: 0.999570
- **Recall**: 1.000000
- **Acur√°cia**: 0.999786
- **AUC**: 1.000000
- **Matriz de confus√£o**: VP=2325, FP=1, VN=2339, FN=0

> Observa√ß√£o: essas m√©tricas s√£o do **split de teste** do dataset **sint√©tico ampliado** (`data/dataset_pedidos_lai_aug.csv`). A avalia√ß√£o oficial do hackathon ocorrer√° no **subconjunto de controle** da CGDF (n√£o dispon√≠vel ao participante).

### Figuras (geradas a partir do modelo exportado)

Para (re)gerar as figuras:

```bash
py .\src\report_plots.py
```

**Matriz de confus√£o**

![](docs/confusion_matrix_tfidf.png)

**Curva ROC**

![](docs/roc_curve_tfidf.png)

**Curva Precision-Recall**

![](docs/pr_curve_tfidf.png)

**Distribui√ß√£o de probabilidades (teste)**

![](docs/proba_hist_tfidf.png)

**Top termos (coeficientes do modelo)**

![](docs/top_features_tfidf.png)

---

## Crit√©rios do edital

O edital mede desempenho por **Precis√£o** e **Recall** e usa a f√≥rmula:

```text
P1 = 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)   (equivalente ao F1)
```

Este reposit√≥rio entrega (reprodut√≠vel):
- um modelo execut√°vel (`models/modelo_tfidf.pkl`) e um script de infer√™ncia (`src/predict_final.py`)
- treino reprodut√≠vel (`src/train.py`) com export de m√©tricas (`models/metricas_tfidf.json`)
- documenta√ß√£o e relat√≥rio t√©cnico (`docs/RELATORIO_TECNICO.md`)

---

## Estrutura do Projeto

```
hackathon_cgdf/
‚îú‚îÄ‚îÄ README.md                          # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt                   # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_pedidos_lai.csv       # Dataset de base (sint√©tico rotulado)
‚îÇ   ‚îî‚îÄ‚îÄ dataset_pedidos_lai_aug.csv   # Dataset ampliado (gerado) para treino
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ modelo_tfidf.pkl              # Modelo principal (TF‚ÄëIDF + LogReg)
‚îÇ   ‚îú‚îÄ‚îÄ threshold.json                # Threshold escolhido (otimiza F1)
‚îÇ   ‚îî‚îÄ‚îÄ metricas_tfidf.json           # M√©tricas do modelo exportadas
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ predict_final.py              # Script de classifica√ß√£o (usa modelo_tfidf.pkl)
‚îÇ   ‚îú‚îÄ‚îÄ train.py                      # Gera√ß√£o de dataset + treino + export
‚îÇ   ‚îî‚îÄ‚îÄ features_pii.py               # Detec√ß√£o explic√°vel (tipos encontrados)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_build_dataset.ipynb        # Notebook: gera√ß√£o do dataset ampliado
‚îÇ   ‚îî‚îÄ‚îÄ 02_train_eval_export.ipynb    # Notebook: treino/avalia√ß√£o/exporta√ß√£o
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ feature_importance_final.png  # Gr√°fico de import√¢ncia das features
```

---

## Instala√ß√£o

### Pr√©-requisitos

- Python 3.9 ou superior
- pip (gerenciador de pacotes Python)

### Passos de Instala√ß√£o

1. **Clone o reposit√≥rio:**
```bash
git clone <URL_DO_REPOSITORIO>
cd hackathon_cgdf
```

2. **Crie um ambiente virtual (recomendado):**
```bash
python -m venv venv
```

3. **Ative o ambiente virtual:**

- Windows:
```bash
venv\Scripts\activate
```

- Linux/Mac:
```bash
source venv/bin/activate
```

4. **Instale as depend√™ncias:**
```bash
pip install -r requirements.txt
```

---

## Uso

### Classifica√ß√£o de um √∫nico pedido

```bash
python src/predict_final.py "Texto do pedido LAI"
```

**Exemplo:**
```bash
python src/predict_final.py "Meu CPF √© 123.456.789-01. Solicito informa√ß√µes sobre meu processo."
```

**Sa√≠da esperada:**
```
======================================================================
RESULTADO DA CLASSIFICA√á√ÉO
======================================================================
Cont√©m dados pessoais: SIM
Confian√ßa: 99.98%
Probabilidade (Sem dados): 0.02%
Probabilidade (Com dados): 99.98%
Tipos de dados encontrados: CPF
Total de padr√µes detectados: 1
======================================================================
```

### Sa√≠da em formato JSON

```bash
python src/predict_final.py "Texto do pedido" --json
```

**Exemplo de sa√≠da JSON:**
```json
{
  "contem_dados_pessoais": true,
  "confianca": 0.9998,
  "probabilidade_sem_dados": 0.0002,
  "probabilidade_com_dados": 0.9998,
  "tipos_dados_encontrados": ["CPF", "RG"],
  "total_padroes": 2,
  "total_tipos": 2
}
```

### Uso como m√≥dulo Python

```python
from src.predict_final import classificar_pedido

# Classificar um pedido
resultado = classificar_pedido("Texto do pedido LAI")

# Acessar resultados
print(resultado['contem_dados_pessoais'])  # True/False
print(resultado['confianca'])              # 0.0 a 1.0
print(resultado['tipos_dados_encontrados']) # Lista de tipos
```

---

## Tipos de Dados Detectados

O modelo identifica os seguintes tipos de dados pessoais:

| Tipo | Padr√£o | Exemplo |
|------|--------|---------|
| **CPF** | `XXX.XXX.XXX-XX` ou 11 d√≠gitos | `123.456.789-01` |
| **RG** | `XX.XXX.XXX-X` | `12.345.678-9` |
| **Telefone** | `(XX) XXXXX-XXXX` | `(61) 91234-5678` |
| **E-mail** | `usuario@dominio.com` | `joao@email.com` |
| **CEP/Endere√ßo** | `XXXXX-XXX` | `70000-000` |
| **Data** | `DD/MM/AAAA` | `01/01/1990` |
| **PIS/PASEP** | `XXX.XXXXX.XX-X` | `123.45678.90-1` |
| **T√≠tulo de Eleitor** | 12 d√≠gitos (com contexto) | `123456789012` |

---

## Metodologia (resumo)

### 1. Dataset

- **Base**: `data/dataset_pedidos_lai.csv` (sint√©tico rotulado existente)
- **Amplia√ß√£o**: `data/dataset_pedidos_lai_aug.csv` gerado por `src/train.py --build-dataset` com:
  - positivos com varia√ß√µes realistas (nome puro, endere√ßo sem CEP, CPF espa√ßado, email ofuscado, etc.)
  - **hard negatives** com padr√µes de n√∫meros comuns em pedidos reais (SEI/protocolo/matr√≠cula/ocorr√™ncia/nota fiscal), usando a amostra `AMOSTRA_e-SIC - Amostra - SIC.csv` como base textual (com *scrub* de PII)
- **Divis√£o**: 70% treino, 15% valida√ß√£o, 15% teste (estratificado, seed fixo)

### 2. Engenharia de Features

Neste projeto, a ‚Äúfeature engineering‚Äù principal √© **textual**, via TF‚ÄëIDF:
- **Word n-grams (1‚Äì2)** para capturar termos como `cpf`, `me chamo`, `meu nome`, `endere√ßo`, etc.
- **Char n-grams (3‚Äì5, char_wb)** para capturar varia√ß√µes de formato (`123 456 789 01`, emails ofuscados, etc.)

### 3. Modelo Utilizado

- **Algoritmo:** TF‚ÄëIDF + Logistic Regression (modelo linear)
- **Threshold tuning:** o limiar de decis√£o √© escolhido para maximizar **F1** na valida√ß√£o (ver `models/threshold.json`)

---

## Resultados da Valida√ß√£o

### Modelos Testados

| Modelo | F1-Score | Precis√£o | Recall | Acur√°cia | AUC |
|--------|----------|----------|--------|----------|-----|
| **TF‚ÄëIDF + Logistic Regression** | **ver `models/metricas_tfidf.json`** |  |  |  |  |

---

## Tecnologias Utilizadas

- **Python 3.9+**
- **Scikit-learn** - Machine Learning
- **Pandas/NumPy** - Manipula√ß√£o de dados
- **Matplotlib/Seaborn** - Visualiza√ß√£o
- **Joblib** - Serializa√ß√£o do modelo

---

## Treino (reprodut√≠vel)

### 1) Gerar dataset ampliado

```bash
py .\src\train.py --build-dataset
```

### 2) Treinar e exportar o modelo

```bash
py .\src\train.py --train
```

### 3) Rodar teste adversarial (100 frases)

```bash
py .\test_frases.py
```

---

## Uso de IA (conforme edital)

O edital permite uso de IA desde que documentado. Caso tenha sido utilizado IA durante o desenvolvimento, listar claramente:
- modelo(s) usados, prompts/assist√™ncia (se aplic√°vel)
- bibliotecas e fontes
- o que foi automatizado vs. o que foi decidido pelo time
*(Ajuste esta se√ß√£o conforme a sua submiss√£o final.)*

---

## üë• Autor

Solu√ß√£o desenvolvida para o **1¬∫ Hackathon em Controle Social - Desafio Participa DF**

Organizado pela: **Controladoria-Geral do Distrito Federal (CGDF)**

---

## üìÑ Licen√ßa

Este projeto foi desenvolvido para fins de competi√ß√£o no Hackathon CGDF.

---

## üìû Contato

Para d√∫vidas ou sugest√µes sobre o projeto, entre em contato atrav√©s do reposit√≥rio.

---

## Observa√ß√µes finais

- O reposit√≥rio cont√©m m√©tricas locais do dataset sint√©tico ampliado e ferramentas para reproduzir o treino.
- A avalia√ß√£o oficial √© feita pela CGDF em subconjunto de controle.
